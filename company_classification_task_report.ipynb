{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Company classification task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from scripts.embedding_rf import train_and_eval_embedding_rf\n",
    "from scripts.bert_eval import evaluate_on_test_set, load_model_and_predict, create_label_encoder\n",
    "from scripts.utils import load_json, visualize_classification_report, plot_model_comparisons\n",
    "\n",
    "from scripts.business_classifier import BusinessClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial variables\n",
    "\n",
    "train_csv_path = 'resources/train.csv'\n",
    "test_csv_path = 'resources/test.csv'\n",
    "\n",
    "bert_folder = 'bert_classifier/'\n",
    "\n",
    "enriched_train_companies_path = 'resources/train_companies.json'\n",
    "enriched_test_companies_path = 'resources/test_companies.json'\n",
    "\n",
    "enriched_train_companies = load_json(enriched_train_companies_path)\n",
    "enriched_test_companies = load_json(enriched_test_companies_path)\n",
    "\n",
    "labels = [\n",
    "        \"Technology hardware & equipment\", \"Food drink & tobacco\", \"Construction\",\n",
    "        \"Health care equipment & services\", \"Conglomerates\", \"Capital goods\",\n",
    "        \"Retailing\", \"Utilities\", \"Food markets\", \"Aerospace & defense\",\n",
    "        \"Materials\", \"Banking\", \"Oil & gas operations\", \"Business services & supplies\",\n",
    "        \"Insurance\", \"Semiconductors\", \"Trading companies\", \"Diversified financials\",\n",
    "        \"Drugs & biotechnology\", \"Telecommunications services\", \"Software & services\",\n",
    "        \"Household & personal products\", \"Hotels restaurants & leisure\", \"Transportation\",\n",
    "        \"Consumer durables\", \"Media\", \"Chemicals\"\n",
    "    ]\n",
    "\n",
    "# Graph classifier paths\n",
    "model_names=[\"all-MiniLM-L6-v2\", \"BAAI/bge-m3\"]\n",
    "business_db_path=\"./chroma_db_biz\"\n",
    "yelp_category_db_path=\"./chroma_db_yelp_cat\"\n",
    "forbes_category_db_path=\"./chroma_db_forbes_cat\"\n",
    "business_collection_name=\"businesses_multi\"\n",
    "category_collection_name=\"categories_multi\"\n",
    "forbes_path=\"./resources/train_companies.json\"\n",
    "yelp2forbes_path=\"./resources/yelp2forbes_business_data.json\"\n",
    "yelp_graph_path=\"./resources/yelp2forbes_categories.graphml\"\n",
    "forbes_graph_path=\"./resources/forbes_categories.graphml\"\n",
    "enrichment_db_path=\"./resources/test_companies.json\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building and enriching the dataset\n",
    "\n",
    "We began by taking our raw dataset.csv of Forbes 2000 companies (with columns COMPANY, CATEGORY) and performing a stratified split per category: 70% of each category’s entries went into `train.csv`, and the remaining 30% into `test.csv`. This ensured that every category was represented proportionally in both training and testing sets, preserving class balance across our supervised experiments.\n",
    "\n",
    "## BigPicture API enrichment\n",
    "\n",
    "Next, for each company in `train.csv` (and later in `test.csv`), we invoked the BigPicture Company Enrichment API in two steps:\n",
    "\n",
    "1. Search by name to retrieve the highest-confidence domain.\n",
    "2. Find by that domain to obtain detailed metadata (tags, category taxonomy, description, LinkedIn handle, etc.).\n",
    "\n",
    "We extracted and saved only the fields we needed—name, domain, confidence, tags, category, linkedin, description, and id, into enriched JSON datasets (`train_companies.json` / `test_companies.json`).\n",
    "\n",
    "## Subcategory graph construction\n",
    "\n",
    "### Forbes subcategory graph \n",
    "\n",
    "Using the enriched Forbes data, we treated each returned tag (e.g., \"B2B\", \"Alumni\", \"Professional Networking\") as a forbes subcategory. We then:\n",
    "\n",
    "1. Prompted a compact `Meta-Llama-3.2-8B-Instruct` model with examples of businesses for each tag to generate a brief “Focus on …” keyword description (up to 5 keywords).\n",
    "2. Embedded these generated descriptions along with the official Forbes category names using a MultiModelEmbedder (concatenated, normalized embeddings from multiple SentenceTransformer models).\n",
    "3. Built a bipartite graph (`resources/forbes_categories.graphml`) where:\n",
    "    - Nodes are subcategories (tags) and Forbes categories.\n",
    "    - Edge weights combine:\n",
    "        - Frequency weight of tag occurrences under each category (normalized per tag), and\n",
    "        - Cosine similarity between tag-description embeddings and category-name embeddings.\n",
    "\n",
    "This graph captures both empirical co-occurrence and semantic relatedness.\n",
    "\n",
    "\n",
    "### Yelp subcategory graph\n",
    "\n",
    "In parallel, we processed the clean Yelp dataset (sourced from Yelp Open Dataset) to extract each business’s granular Yelp categories (e.g., \"Bubble Tea\", \"Hair Salons\"). We:\n",
    "\n",
    "- Sampled up to five businesses per Yelp category and prompted the same Meta-Llama model to produce concise \"Focus on ...\" keyword descriptions.\n",
    "- Computed embeddings and constructed a second bipartite graph (`resources/yelp_categories.graphml`) linking Yelp subcategories to the same set of Forbes categories, embedding based cosine similarity on edges.\n",
    "\n",
    "## Vector databases for retrieval\n",
    "\n",
    "Finally, we created local ChromaDB vector stores for:\n",
    "\n",
    "1. Forbes subcategory embeddings (tag descriptions) - `chroma_db_forbes_cat/`,\n",
    "2. Yelp subcategory embeddings (category descriptions) - `chroma_db_yelp_cat/`,\n",
    "3. Company name embeddings (from the enriched datasets) - `chroma_db_biz/`\n",
    "\n",
    "These vector DBs support fast nearest-neighbor retrieval for downstream RAG pipelines, similarity-based classification, and interactive analysis—tying together our enriched metadata, semantic graphs, and classification engines into a unified, high-performance system.\n",
    "\n",
    "\n",
    "Example of bipartite graph:\n",
    "\n",
    "![](./docs/Graph.drawio.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest with embeddings classifier\n",
    "\n",
    "By using multi-embeddings from different `SentenceTransformer` models, I embedded the company names and tried to build a simple random forest classifier for the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_rf, y_pred_rf = train_and_eval_embedding_rf(train_csv_path,test_csv_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_classification_report(y_true_rf, y_pred_rf, [l.lower() for l in labels], output_dir='results_rf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since the training set might be overrepresented with banking category examples, we can clearly see how the classifier was overbiased towards the banking category, often misclassifying other companies as banking, leading to loss in performance. The classifier did achieve relatively good accuracy due to correctly classifying the largest category, however it feel short in overall F1 score.\n",
    "\n",
    "![](./results_rf/category_accuracy.png)\n",
    "\n",
    "![](./results_rf/confusion_matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT based sequence classifier\n",
    "\n",
    "Using an encoder BERT for sequence classification, I fine-tuned the `bert-base-uncased` pretrained model for task of business category classification. By using the company names and descriptions as input and labels as output, we can train the model to perform relatively well for the task. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true_bert, y_pred_bert = evaluate_on_test_set(train_csv_path, test_csv_path, enriched_test_companies_path, bert_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_classification_report(y_true_bert, y_pred_bert, [l.lower() for l in labels], output_dir='results_bert')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: oil & gas operations\n"
     ]
    }
   ],
   "source": [
    "# Prediction on single example from test set\n",
    "\n",
    "COMPANY_NAME = 'ExxonMobil'\n",
    "\n",
    "enriched_data = {entry[\"name\"].strip().lower(): entry for entry in enriched_test_companies if entry[\"name\"] != None}\n",
    "\n",
    "le = create_label_encoder(train_csv_path)\n",
    "\n",
    "res = load_model_and_predict(bert_folder, COMPANY_NAME, enriched_data, le)\n",
    "\n",
    "print(f'Predicted: {res}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the results we can observe that the model performs great in classifying specific categories, achieveing high recall, however it does not work well on other categories, where the companies might be also diversified in other categories, such as conglomerates, trading companies, diversified financials... From confusion matrix we can also see that the diversified financials were often misclassified with other categories or for example misclassification between banking and diversified financial (very similar semantic meaning). \n",
    "\n",
    "![](./results_bert/category_accuracy.png)\n",
    "\n",
    "![](./results_bert/confusion_matrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph based classifier\n",
    "\n",
    "The graph based classifier works based on precomputed company embeddings from `train.csv` and precomputed company category subcategories. \n",
    "\n",
    "Steps:\n",
    "1. The queried company name string to predict is first embedded using multiple `SentenceTransformer` models (`all-MiniLM-L6-v2, BAAI/bge-m3`) to create vector representations of the tokens in the string.\n",
    "2. We query the company name embedding database, where I have stored embedded vectors from company names in `train.csv`. The returned result are top@k companies which are similar to the queried company name. In case, I observe very high similarity with other company names (is above some threshold $\\alpha = 0.9$), I store the category results for the most similar company above threshold.\n",
    "3. On the other side, I can either decide to use BigPicture API, which can provide us with up-to-date details and description about the company. I can either use this API or not, however it helps in cases, when the company name is too ambigious to actually classify as something.\n",
    "\n",
    "> In our case, I have queried the API and got results for most of companies in `dataset.csv`, so that I can re-use the API results without reaching the API limit. The BigPicture API also provides us with it's own category classification, however I will be using only the description of the company returned from the API.\n",
    "\n",
    "\n",
    "4. Based on enriched company description or company name, I query the vector databases for closest subcategories in both Yelp and Forbes subcategories datasets, which I created. This will get us top@k subcategory nodes, which have closest embeddings descriptions to the company description or company name.\n",
    "5. Afterwards, the derived scores will be computed from the bipartite graph, which was created earlier:\n",
    "    For each of the graphs:\n",
    "\n",
    "    1. We get the subcategory nodes which were collected from step 4 (e.g. Finance, Wealth Management, Loans...)\n",
    "    2. Each subcategory is connected to the classification nodes with some edge weights\n",
    "    3. For each subcategory node, get all the connected edge weights to classification node weights, sum them and normalize\n",
    "    4. This will get us a dictionary of scores for all categories (e.g. Banking, Diversified Financials...)\n",
    "Combine the results from both graph with some factor $\\beta$ -> Scores = Yelp $\\cdot \\beta +(1-\\beta) \\cdot$ Forbes \n",
    "\n",
    "6. If we have stored high company similarity from step 2, combine them into final scores, giving boost to category that is very similar with the queried company. Get the prediction with the highest score.\n",
    "\n",
    "\n",
    "\n",
    "![](./docs/Graph%20classifier.drawio.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding models: all-MiniLM-L6-v2, BAAI/bge-m3\n",
      "Loading business database from ./chroma_db_biz\n",
      "Successfully loaded business collection 'businesses_multi'\n",
      "Loading Yelp category database from ./chroma_db_yelp_cat\n",
      "Successfully loaded Yelp category collection 'categories_multi'\n",
      "Loading Forbes category database from ./chroma_db_forbes_cat\n",
      "Successfully loaded Forbes category collection 'categories_multi'\n",
      "Loading Yelp category graph from ./resources/yelp2forbes_categories.graphml\n",
      "Successfully loaded graph with 631 nodes and 16386 edges\n",
      "Loading Forbes category graph from ./resources/forbes_categories.graphml\n",
      "Successfully loaded graph with 579 nodes and 14904 edges\n",
      "Loaded 27 classification categories\n",
      "Loaded 604 Yelp subcategories\n",
      "Loaded 552 Forbes subcategories\n",
      "Loading company data from ./resources/train_companies.json\n",
      "Loaded 1112 company records\n",
      "Loading Yelp to Forbes mapping from ./resources/yelp2forbes_business_data.json\n",
      "Loaded 114023 Yelp-Forbes mappings\n"
     ]
    }
   ],
   "source": [
    "classifier = BusinessClassifier(\n",
    "    model_names=model_names,\n",
    "    business_db_path=business_db_path,\n",
    "    yelp_category_db_path=yelp_category_db_path,\n",
    "    forbes_category_db_path=forbes_category_db_path,\n",
    "    business_collection_name=business_collection_name,\n",
    "    category_collection_name=category_collection_name,\n",
    "    forbes_path=forbes_path,\n",
    "    yelp2forbes_path=yelp2forbes_path,\n",
    "    yelp_graph_path=yelp_graph_path,\n",
    "    forbes_graph_path=forbes_graph_path,\n",
    "    enrichment_db_path=enrichment_db_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Evaluation with raw business names\n",
    "evaluation_results = classifier.evaluate(\n",
    "    test_file_path=test_csv_path,\n",
    "    results_dir=\"results\",\n",
    "    use_enrichment=False,\n",
    "    top_k_businesses=3,\n",
    "    top_k_yelp=10,\n",
    "    top_k_forbes=10,\n",
    "    beta=0.2\n",
    ")\n",
    "\n",
    "# Evaluation with enriched business descriptions\n",
    "evaluation_results = classifier.evaluate(\n",
    "    test_file_path=test_csv_path,\n",
    "    results_dir=\"results_enriched\",\n",
    "    use_enrichment=True,\n",
    "    top_k_businesses=3,\n",
    "    top_k_yelp=10,\n",
    "    top_k_forbes=10,\n",
    "    beta=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction on single example from test set\n",
    "\n",
    "COMPANY_NAME = 'ExxonMobil'\n",
    "\n",
    "res_g = classifier.predict(\n",
    "    # Business name\n",
    "    business_name=COMPANY_NAME,\n",
    "\n",
    "    # Whether to add more context to business name from API (precomputed on test set)\n",
    "    use_enrichment=True,\n",
    "    \n",
    "    # Other variables...\n",
    "    beta=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: Oil & gas operations\n"
     ]
    }
   ],
   "source": [
    "print(f'Predicted: {res_g[\"predictions\"][0][\"category\"]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw business name classifier results\n",
    "\n",
    "We can see the category wise accuracy performance on the test set. Because of the unbalanced set, some subcategories might underrepresent classification nodes, meaning they will are less likely to be classified. Retailing for example had a lot of misclassifications in other categories, most likely because it is a more general term, which can be tightly connected also with a lot of other categories.\n",
    "\n",
    "![](./results/category_accuracy.png)\n",
    "\n",
    "![](./results/confusion_matrix.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enriched business name with description classifier results\n",
    "\n",
    "Overall, enriching the business names with descriptions gave boost to the performance, however it still suffered from some categories being underrepresented and less likely to be correctly classified. We can see that in some cases, enriching the description also misclassified some categories completely as compared from before (`Food markets`).\n",
    "\n",
    "![](./results_enriched/category_accuracy.png)\n",
    "\n",
    "![](./results_enriched/confusion_matrix.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparisons between classifiers\n",
    "\n",
    "Here we can overall see the performance comparisons between the models that we created for the task. Overall the enriched graph classifier and enriched BERT classifier performed the best achieving ~47% accuracy for both. However, the graph classifier performed faster classifications as it worked with already precomputed embeddings, instead of actually performing more complex computations and inference as BERT model, therefore producing faster classifications.\n",
    "\n",
    "![](./docs/model_comparison.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_models_evals = [\n",
    "    'results_rf/classification_report.json',\n",
    "    'results_bert/classification_report.json',\n",
    "]\n",
    "\n",
    "graph_results = [\n",
    "    'results/evaluation_results.json',\n",
    "    'results_enriched/evaluation_results.json'\n",
    "]\n",
    "\n",
    "plot_model_comparisons(base_models_evals, graph_results, labels=['Random Forest', 'Enriched BERT Classifier', 'Graph classifier', 'Enriched graph classifier'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Possible improvements\n",
    "\n",
    "- While some models perform better on some categories, we could use the basic type of models for some faster and more simpler classifications (e.g. classifying banking or telecommunication service companies). However, other categories which might be harder to classify should be handled by other models, specifically fine-tuned on classifying those categories, this way they can complement each other and help get better results (sort of ensemble of classifiers).\n",
    "\n",
    "- There is also the problem of ambiguity with companies, as some companies might not be so obvious to detect from name, therefore it's helpful to provide even more context and relevant up-to-date information about the company as it might help with giving more representation insights to the models. If we were working with unseen business company names we could also clean text and improve the names.\n",
    "\n",
    "- We could also utilize a very large LLM, such as querying or using the OpenAI embeddings to help us with predictions, maybe as using it as the last step to help us get the most up-to-date and accurate final prediction\n",
    "    - In that case, we could use the previous predictions from other models and returned closest similar subcategories to provide to the prompt as RAG (retrieval augmented generation) that would help the LLM by providing it with more context\n",
    "    - Furthermore, the large LLM could also help disambiguate between harder examples, such as conglomerates, trading companies, narrowing down the exact industry, even perhaps providing few-shot examples of those categories to help with classification\n",
    "    - In our case, we observed that many companies were incorrectly classified into broad categories like `Business Services & Supplies` and `Retailing`. To address this, whenever our base classifier predicts one of these \"risky\" classes, we can trigger a second opinion model, such as an LLM using RAG (Retrieval-Augmented Generation). The LLM would re-evaluate the prediction by considering additional context and company details. We could guide the model by providing a limited set of alternative classes to choose from, based on common misclassification patterns.\n",
    "```\n",
    "Given this company and its description, decide between Trading Company, Retailing, or Conglomerate.\n",
    "Company: [ENRICHED COMPANY INFORMATION]\n",
    "Here are some examples of (business name, category) pairs: [EXAMPLES]\n",
    "You may only output these classes: Trading Company, Retailing, or Conglomerate.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Improving business classification could involve balancing accuracy with efficiency. One approach is using a multi-model ensemble, where simpler models handle easy-to-classify categories (e.g., Banking, Telecommunications) quickly and cost-effectively, while specialized models fine-tuned for harder categories handle more complex cases. This strategy ensures both speed and accuracy.\n",
    "\n",
    "Additionally, incorporating contextual information, such as company descriptions or enriched data, helps address ambiguity in company names, especially for businesses with complex or overlapping industries.\n",
    "\n",
    "By leveraging these techniques, we can optimize accuracy and reduce resource consumption, ensuring a balance between performance and cost efficiency, crucial when dealing with large-scale classification tasks."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
